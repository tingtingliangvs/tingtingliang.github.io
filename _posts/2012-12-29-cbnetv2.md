---
layout: distill
title: 'CBNet: A Composite Backbone Network Architecture for Object Detection'
description: TIP
giscus_comments: true
date: 2022-12-28

authors:
  - name: Tingting Liang
    url: "https://tingtingliangvs.github.io"
    affiliations:
      name: Peking University

# bibliography: 2018-12-22-distill.bib

# Optionally, you can add a table of contents to your post.
# NOTES:
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
#   - we may want to automate TOC generation in the future using
#     jekyll-toc plugin (https://github.com/toshimaru/jekyll-toc).
toc:
  - name: Abstract
    # if a section has subsections, you can add them as follows:
    # subsections:
    #   - name: Example Child Subsection 1
    #   - name: Example Child Subsection 2
  - name: Results
  - name: Further Information


# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }

---

## Abstract

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/cbnet/pipeline.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Illustration of the proposed Composite Backbone Network (CBNet) architecture for object detection.
</div>

Modern top-performing object detectors depend heavily on backbone networks, whose advances bring consistent performance gains through exploring more effective network structures.  In this paper, we propose a novel and flexible backbone framework, namely , to construct high-performance detectors using existing open-source pre-trained backbones under the pre-training fine-tuning paradigm.  In particular, CBNet architecture groups multiple identical backbones, which are connected through composite connections. Specifically, it integrates the high- and low-level features of multiple identical backbone networks and gradually expands the receptive field to more effectively perform object detection. We also propose a better training strategy with auxiliary supervision for CBNet-based detectors. CBNet has strong generalization capabilities for different backbones and head designs of the detector architecture. Without additional pre-training of the composite backbone, CBNet can be adapted to various backbones (i.e., CNN-based vs. Transformer-based) and head designs of most mainstream detectors (i.e., one-stage vs. two-stage, anchor-based vs. anchor-free-based). Experiments provide strong evidence that, compared with simply increasing the depth and width of the network, CBNet introduces a more efficient, effective, and resource-friendly way to build high-performance backbone networks. Particularly, our CB-Swin-L achieves 59.4% box AP and 51.6% mask AP on COCO test-dev under the single-model and single-scale testing protocol, which are significantly better than the state-of-the-art results (i.e., 57.7% box AP and 50.2% mask AP) achieved by Swin-L, while reducing the training time by 6x. With multi-scale testing, we push the current best single model result to a new record of 60.1% box AP and 52.3% mask AP without using extra training data.


## Results

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/cbnet/compare.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Performance comparison of CBNet with different numbers of composite backbones (K) and pruning strategies.
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/cbnet/coco.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Comparison with the state-of-the-art object detection and instance segmentation results on COCO.  In collaboration with Swin Transformer, our CBNet achieves the state-of-the-art box AP and mask AP while using fewer training epochs.
</div>

## Further Information

For more detailed information, check out our [paper](https://arxiv.org/abs/2107.00420) and [code](https://github.com/VDIGPKU/CBNetV2). We are happy to receive your feedback!

```
@article{DBLP:journals/tip/LiangCLWTCCL22,
  author    = {Ting{-}Ting Liang and
               Xiaojie Chu and
               Yudong Liu and
               Yongtao Wang and
               Zhi Tang and
               Wei Chu and
               Jingdong Chen and
               Haibin Ling},
  title     = {CBNet: {A} Composite Backbone Network Architecture for Object Detection},
  journal   = {IEEE Trans. Image Process.},
  volume    = {31},
  pages     = {6893--6906},
  year      = {2022},
  url       = {https://doi.org/10.1109/TIP.2022.3216771},
  doi       = {10.1109/TIP.2022.3216771},
  timestamp = {Mon, 05 Dec 2022 13:33:25 +0100},
  biburl    = {https://dblp.org/rec/journals/tip/LiangCLWTCCL22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}
```

